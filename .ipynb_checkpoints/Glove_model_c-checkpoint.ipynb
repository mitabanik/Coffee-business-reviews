{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1bc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
    "from keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13d29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"coffee_reviews.csv\")\n",
    "#data=data.loc[data['stars_x']>=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaaaab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/58/fw1mf93d4gxg7d40q7fc5hj00000gn/T/ipykernel_792/3415193883.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['clean_text']= data.text.str.replace('\\n',''). \\\n"
     ]
    }
   ],
   "source": [
    "data['sentiment'] = 0* data['stars_x']\n",
    "def sent(num):\n",
    "    num=int(num)\n",
    "    if num<=3:\n",
    "        return 0\n",
    "    if num>3:\n",
    "        return 1\n",
    "data['sentiment']=data.stars_x.apply(sent)\n",
    "data.text = data.text.str.lower()\n",
    "\n",
    "## remove unnecessary punctuation\n",
    "data['clean_text']= data.text.str.replace('\\n',''). \\\n",
    "                                          str.replace('[!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52da4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X,X_test,y,y_test = train_test_split(data,data.sentiment,stratify=data.sentiment,test_size=0.2,random_state=11)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(data,data.sentiment,stratify=data.sentiment,test_size=0.3,random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb8076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1015416it [00:59, 15953.85it/s]"
     ]
    }
   ],
   "source": [
    "#using glove embeddings\n",
    "from tqdm import tqdm\n",
    "embeddings_index = {}\n",
    "f = open('glove.840B.300d.txt')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    try:\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "    except ValueError :\n",
    "        continue\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3baf38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2vec(s):\n",
    "    words = str(s)\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_glove = [sent2vec(x) for x in tqdm(x_train.clean_text)]\n",
    "xvalid_glove = [sent2vec(x) for x in tqdm(x_valid.clean_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6daaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_glove = np.array(xtrain_glove)\n",
    "xvalid_glove = np.array(xvalid_glove)\n",
    "xtrain_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca527200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling train and validation sets\n",
    "scl = preprocessing.StandardScaler()\n",
    "xtrain_glove_scl = scl.fit_transform(xtrain_glove)\n",
    "xvalid_glove_scl = scl.transform(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d090c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4f7d521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_enc = np_utils.to_categorical(y_train)\n",
    "yvalid_enc = np_utils.to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c402e2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 128)               38528     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 100)               12900     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,142\n",
      "Trainable params: 72,486\n",
      "Non-trainable params: 656\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_dim=300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'],)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "15caffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6052/6052 [==============================] - 12s 2ms/step - loss: 0.3603 - accuracy: 0.8381 - val_loss: 0.3201 - val_accuracy: 0.8669\n",
      "Epoch 2/5\n",
      "6052/6052 [==============================] - 12s 2ms/step - loss: 0.3596 - accuracy: 0.8392 - val_loss: 0.3245 - val_accuracy: 0.8656\n",
      "Epoch 3/5\n",
      "6052/6052 [==============================] - 12s 2ms/step - loss: 0.3584 - accuracy: 0.8392 - val_loss: 0.3085 - val_accuracy: 0.8698\n",
      "Epoch 4/5\n",
      "6052/6052 [==============================] - 12s 2ms/step - loss: 0.3565 - accuracy: 0.8398 - val_loss: 0.3069 - val_accuracy: 0.8703\n",
      "Epoch 5/5\n",
      "6052/6052 [==============================] - 12s 2ms/step - loss: 0.3545 - accuracy: 0.8399 - val_loss: 0.3154 - val_accuracy: 0.8627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7a3584220>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_glove_scl, y=ytrain_enc, batch_size=64, \n",
    "          epochs=100, verbose=1,\n",
    "          validation_data=(xvalid_glove_scl, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6b2f4274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1163/1163 [==============================] - 1s 797us/step - loss: 0.3154 - accuracy: 0.8627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31541869044303894, 0.8626834154129028]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xvalid_glove_scl, yvalid_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3e2ff492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701553512874267"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(model.predict(xvalid_glove_scl),axis=1)==y_test)/len(xvalid_glove_scl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a9dd044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9331223 , 0.06687769],\n",
       "       [0.92002726, 0.07997274],\n",
       "       [0.8033744 , 0.19662559],\n",
       "       ...,\n",
       "       [0.06027746, 0.93972254],\n",
       "       [0.47362518, 0.5263748 ],\n",
       "       [0.3422405 , 0.6577595 ]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred= model.predict(xvalid_glove_scl)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "417a87b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8686,  2242],\n",
       "       [ 2589, 23689]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "552e5ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4836.78"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)*.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "961c1652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.696957\n",
       "0    0.303043\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d14d8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "xst=np.array(x_test.stars_x)\n",
    "yst=np.array(x_test.stars_y)\n",
    "#tt=np.array(x_test.text)\n",
    "err=[];err1=[];err3=[]\n",
    "count=0\n",
    "yt=np.array(x_test.sentiment)\n",
    "for i in range(len(pred)):\n",
    "    predict=np.argmax(pred[i])\n",
    "    \n",
    "    if predict != yt[i] :\n",
    "        count+=1\n",
    "        err.append(xst[i])\n",
    "        err1.append(yst[i])\n",
    "        if xst[i]==3:\n",
    "            #print(tt[i])\n",
    "            err3.append(pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9eaf67d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5109"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "66f96092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 4095, 4: 9427, 3: 4199, 5: 16504, 2: 2981})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(xst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "54f6fbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 2032, 5: 984, 2: 367, 1: 181, 3: 1545})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9802adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          301     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.71161D+04    |proj g|=  1.85302D+04\n",
      "\n",
      "At iterate   50    f=  3.73050D+04    |proj g|=  3.60635D+01\n",
      "\n",
      "At iterate  100    f=  3.73015D+04    |proj g|=  7.58883D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, verbose=1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  301    141    151      1     0     0   4.094D-01   3.730D+04\n",
      "  F =   37301.442777996926     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lreg=LogisticRegression(max_iter=1000,verbose=1,class_weight='balanced')\n",
    "lreg.fit(xtrain_glove_scl,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c0926157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8290783657619697"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.score(xtrain_glove_scl,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55762a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348653442993066"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg.score(xvalid_glove_scl,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3f2bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=lreg.predict(xvalid_glove_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "370dbeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict(scl.transform(np.array(sent2vec(x_test.loc[i,'text']))))\n",
    "#model.predict(scl.transform(np.array(sent2vec(x_test.loc[i,'text'])).reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "488871bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "449fa4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28765521690049994"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.argmax(model.predict(xvalid_glove_scl),axis=1)==0)/len(xvalid_glove_scl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "08701a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.696945\n",
       "0    0.303055\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3d8bfef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 50\n",
    "\n",
    "token.fit_on_texts(list(x_train.clean_text) + list(x_test.clean_text))\n",
    "xtrain_seq = token.texts_to_sequences(x_train.clean_text)\n",
    "xvalid_seq = token.texts_to_sequences(x_test.clean_text)\n",
    "\n",
    "# zero pad the sequences\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d41da0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 152678/152678 [00:02<00:00, 72597.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# create an embedding matrix for the words we have in the dataset\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "642ef51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "#model.add(LSTM(1028, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9914afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "190/190 [==============================] - 100s 514ms/step - loss: 0.5199 - accuracy: 0.7372 - val_loss: 0.4289 - val_accuracy: 0.8162\n",
      "Epoch 2/5\n",
      "190/190 [==============================] - 98s 515ms/step - loss: 0.4408 - accuracy: 0.7942 - val_loss: 0.3751 - val_accuracy: 0.8481\n",
      "Epoch 3/5\n",
      "190/190 [==============================] - 95s 497ms/step - loss: 0.4133 - accuracy: 0.8085 - val_loss: 0.3819 - val_accuracy: 0.8480\n",
      "Epoch 4/5\n",
      "190/190 [==============================] - 95s 502ms/step - loss: 0.3952 - accuracy: 0.8188 - val_loss: 0.3522 - val_accuracy: 0.8620\n",
      "Epoch 5/5\n",
      "190/190 [==============================] - 93s 489ms/step - loss: 0.3795 - accuracy: 0.8286 - val_loss: 0.3483 - val_accuracy: 0.8586\n"
     ]
    }
   ],
   "source": [
    "history =model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=5, verbose=1, validation_data=(xvalid_pad, yvalid_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(300, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['AUC'])\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=50, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7277e775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "190/190 [==============================] - 77s 396ms/step - loss: 0.5342 - accuracy: 0.7337 - val_loss: 0.3786 - val_accuracy: 0.8271\n",
      "Epoch 2/5\n",
      "190/190 [==============================] - 76s 399ms/step - loss: 0.4365 - accuracy: 0.8001 - val_loss: 0.3408 - val_accuracy: 0.8503\n",
      "Epoch 3/5\n",
      "190/190 [==============================] - 75s 396ms/step - loss: 0.4120 - accuracy: 0.8131 - val_loss: 0.3380 - val_accuracy: 0.8530\n",
      "Epoch 4/5\n",
      "190/190 [==============================] - 76s 400ms/step - loss: 0.3974 - accuracy: 0.8204 - val_loss: 0.3211 - val_accuracy: 0.8600\n",
      "Epoch 5/5\n",
      "190/190 [==============================] - 75s 394ms/step - loss: 0.3870 - accuracy: 0.8262 - val_loss: 0.3260 - val_accuracy: 0.8574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc73cc965e0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU with glove embeddings and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(GRU(100, dropout=0.3, recurrent_dropout=0.3\n",
    "             ))\n",
    "#model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=5, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d3ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
